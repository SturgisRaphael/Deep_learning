{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkkAFuMGsfou"
   },
   "source": [
    "<h1>TP3 Deep Learning</h1>\n",
    "\n",
    "Cette troisième séance porte sur la découverte des réseaux de convolutions :\n",
    "* Retour sur MNIST\n",
    "* Première architecture convolutionnelle\n",
    "* Visualisation des filtres\n",
    "* Utilisation de VGG16, un réseau pré-entrainé\n",
    "* Visualisation des filtres par maximisation des activations\n",
    "* Augmentation de données\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Ua8jKmisfov"
   },
   "outputs": [],
   "source": [
    "venv_root = '/amuhome/sturgis/deep'    # A modifier !!\n",
    "\n",
    "import sys\n",
    "sys.path.append(venv_root+'/lib/python3.5/site-packages')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sLtROamlsfo0"
   },
   "source": [
    "Import des premiers packages nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DDKhM0Dvsfo0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b_E-9SHIsfo9"
   },
   "source": [
    "<h2> Chargement des données</h2>\n",
    "\n",
    "Ici on charge le jeu de données MNIST (les chiffres manuscrits), puis quelques instructions de mise en forme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n0CEtl53sfo-"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "nb_samples = len(x_train)\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJuOtYO0sfpB"
   },
   "source": [
    "Le jeu de données MNIST contient 60000 exemples répartis en 10 classes. Nous allons ici en sélectionner aléatoirement un certain nombre pour accélérer les étapes suivantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T-tQbYmjsfpB"
   },
   "outputs": [],
   "source": [
    "l_idx = list(range(nb_samples))\n",
    "np.random.shuffle(l_idx) \n",
    "l_idx = l_idx[:10000]\n",
    "\n",
    "x_train, y_train = x_train[l_idx], y_train[l_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lpt5ycb5sfpE"
   },
   "source": [
    "Il est d'abord nécessaire de formater les vecteurs d'étiquettes en <i>one-hot vectors</i> de tailles num_classes. Ces vecteurs contiennent des 0 et un seul 1 par ligne à l'indice correspondant à la classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XiFAbfjdsfpF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eGHETB7sfpI"
   },
   "source": [
    "<h3> Réseau \"Dense\"</h3>\n",
    "\n",
    "Reprenons le réseau considéré à la fin du premier TP. Notez son nombre de paramètres et sa performance obtenue, ils nous serviront de référence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nllXdJabsfpJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 937,482\n",
      "Trainable params: 937,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "9000/9000 [==============================] - 3s 286us/step - loss: 0.5712 - acc: 0.8287 - val_loss: 0.2830 - val_acc: 0.9150\n",
      "Epoch 2/20\n",
      "9000/9000 [==============================] - 2s 200us/step - loss: 0.2159 - acc: 0.9342 - val_loss: 0.2068 - val_acc: 0.9410\n",
      "Epoch 3/20\n",
      "9000/9000 [==============================] - 2s 194us/step - loss: 0.1344 - acc: 0.9602 - val_loss: 0.2051 - val_acc: 0.9420\n",
      "Epoch 4/20\n",
      "9000/9000 [==============================] - 2s 195us/step - loss: 0.0936 - acc: 0.9712 - val_loss: 0.1881 - val_acc: 0.9460\n",
      "Epoch 5/20\n",
      "9000/9000 [==============================] - 2s 199us/step - loss: 0.0713 - acc: 0.9779 - val_loss: 0.1689 - val_acc: 0.9640\n",
      "Epoch 6/20\n",
      "9000/9000 [==============================] - 2s 206us/step - loss: 0.0485 - acc: 0.9840 - val_loss: 0.1866 - val_acc: 0.9490\n",
      "Epoch 7/20\n",
      "9000/9000 [==============================] - 2s 215us/step - loss: 0.0380 - acc: 0.9881 - val_loss: 0.1667 - val_acc: 0.9540\n",
      "Epoch 8/20\n",
      "9000/9000 [==============================] - 2s 209us/step - loss: 0.0343 - acc: 0.9889 - val_loss: 0.1998 - val_acc: 0.9550\n",
      "Epoch 9/20\n",
      "9000/9000 [==============================] - 2s 221us/step - loss: 0.0291 - acc: 0.9913 - val_loss: 0.1849 - val_acc: 0.9570\n",
      "Epoch 10/20\n",
      "9000/9000 [==============================] - 2s 215us/step - loss: 0.0198 - acc: 0.9941 - val_loss: 0.1583 - val_acc: 0.9680\n",
      "Epoch 11/20\n",
      "9000/9000 [==============================] - 2s 203us/step - loss: 0.0178 - acc: 0.9951 - val_loss: 0.1709 - val_acc: 0.9680\n",
      "Epoch 12/20\n",
      "9000/9000 [==============================] - 2s 220us/step - loss: 0.0155 - acc: 0.9944 - val_loss: 0.2024 - val_acc: 0.9530\n",
      "Epoch 13/20\n",
      "9000/9000 [==============================] - 2s 219us/step - loss: 0.0212 - acc: 0.9927 - val_loss: 0.1840 - val_acc: 0.9620\n",
      "Epoch 14/20\n",
      "9000/9000 [==============================] - 2s 220us/step - loss: 0.0192 - acc: 0.9942 - val_loss: 0.1791 - val_acc: 0.9610\n",
      "Epoch 15/20\n",
      "9000/9000 [==============================] - 2s 219us/step - loss: 0.0105 - acc: 0.9970 - val_loss: 0.2129 - val_acc: 0.9570\n",
      "Epoch 16/20\n",
      "9000/9000 [==============================] - 2s 220us/step - loss: 0.0165 - acc: 0.9949 - val_loss: 0.2150 - val_acc: 0.9560\n",
      "Epoch 17/20\n",
      "9000/9000 [==============================] - 2s 225us/step - loss: 0.0177 - acc: 0.9940 - val_loss: 0.2315 - val_acc: 0.9600\n",
      "Epoch 18/20\n",
      "9000/9000 [==============================] - 2s 207us/step - loss: 0.0154 - acc: 0.9954 - val_loss: 0.2077 - val_acc: 0.9610\n",
      "Epoch 19/20\n",
      "9000/9000 [==============================] - 2s 198us/step - loss: 0.0101 - acc: 0.9968 - val_loss: 0.2228 - val_acc: 0.9560\n",
      "Epoch 20/20\n",
      "9000/9000 [==============================] - 2s 207us/step - loss: 0.0167 - acc: 0.9943 - val_loss: 0.2151 - val_acc: 0.9570\n",
      "score= [0.17072922613533156, 0.9624]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "loss = model.fit(x_train, y_train, batch_size=128, epochs=20, validation_split=0.1, callbacks=[], verbose=1)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"score=\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m-732BjGsfpL"
   },
   "source": [
    "<h3>Première architecture convolutionnelle</h3>\n",
    "\n",
    "Créons un nouveau réseau dont les couches Dense (sauf la dernière pour la classification) sont remplacées par des Conv2D, suivis de MaxPooling2D. Notons que la couche \"Flatten\" n'est pas utilisée en début de réseau, puisque les données du réseau sont supposées 2D. En revanche, la couche Dense en bout de réseau suppose des données d'entrée en 1D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UPjwCntOv49R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                11530     \n",
      "=================================================================\n",
      "Total params: 234,634\n",
      "Trainable params: 234,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(64, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu', input_shape=input_shape))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "model2.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "model2.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-PgZYoiGyKag"
   },
   "source": [
    "<b>A faire :</b> Expliquez les nombres de paramètres de chaque couche\n",
    "\n",
    "<h4>Entrainement du réseau :</h4>\n",
    "\n",
    "Appelons maintenant les fonctions fit et evaluate pour entrainer et tester le réseau. Visualisez la courbe d'apprentissage pour vérifier que tout s'apprend bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L2_ravRc0Fvh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "9000/9000 [==============================] - 22s 2ms/step - loss: 0.7333 - acc: 0.7674 - val_loss: 0.1815 - val_acc: 0.9500\n",
      "Epoch 2/20\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.1455 - acc: 0.9556 - val_loss: 0.0983 - val_acc: 0.9730\n",
      "Epoch 3/20\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.0935 - acc: 0.9729 - val_loss: 0.0836 - val_acc: 0.9760\n",
      "Epoch 4/20\n",
      "9000/9000 [==============================] - 25s 3ms/step - loss: 0.0791 - acc: 0.9758 - val_loss: 0.0896 - val_acc: 0.9780\n",
      "Epoch 5/20\n",
      "9000/9000 [==============================] - 24s 3ms/step - loss: 0.0576 - acc: 0.9808 - val_loss: 0.0862 - val_acc: 0.9740\n",
      "Epoch 6/20\n",
      "3072/9000 [=========>....................] - ETA: 17s - loss: 0.0530 - acc: 0.9814"
     ]
    }
   ],
   "source": [
    "loss = model2.fit(x_train, y_train, batch_size=128, epochs=20, validation_split=0.1, callbacks=[], verbose=1)\n",
    "\n",
    "score = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"score=\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mq1pJA_i0VHm"
   },
   "source": [
    "<h4>Visualisation des cartes</h4>\n",
    "\n",
    "Une carte \"réponse\" (ou feature map) d'une couche de convolution correspond à l'état des activations en sortie d'une telle couche. Leur contenu dépend donc d'une image passée en entrée du réseau. \n",
    "\n",
    "Une couche définie pour apprendre 64 filtres de convolution, génère ainsi 64 cartes. On définie d'abord une fonction pour l'affichage d'un tableau d'images (via matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFe_Le1A71sV"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_images(images, cols = 1):\n",
    "    \n",
    "    n_images = len(images)\n",
    "    fig = plt.figure()\n",
    "    for n, image in enumerate(images):\n",
    "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
    "        plt.axis('off')\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QyLX83L1A8oA"
   },
   "source": [
    "Une manière simple pour obtenir ces cartes, via l'API Keras, consiste à faire passer une image (au choix mais de la bonne taille) à travers un réseau tronqué à la couche dont on veut visualiser les sorties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LxwKrb9G0UqV"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "# Définition d'un modèle via la \"graph\" API de Keras\n",
    "model_tmp = Model(model2.layers[0].input, model2.layers[0].output)\n",
    "\n",
    "# Cartes réponses de x_test[10] (un '0')\n",
    "feature_maps = model_tmp.predict(np.expand_dims(x_test[10], 0))\n",
    "\n",
    "# normalisation des valeurs entre 0 et 1\n",
    "minimum, maximum = np.min(feature_maps), np.max(feature_maps)\n",
    "feature_maps = (feature_maps - minimum) / (maximum - minimum)\n",
    "\n",
    "print(minimum, maximum, feature_maps.shape)\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "images = []\n",
    "for i in range(64):\n",
    "  images.append(np.array(255*feature_maps[:,:,:,i]).reshape(28,28).astype('uint8'))\n",
    "\n",
    "show_images(images, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7I0Sk3WWKhci"
   },
   "source": [
    "Les images obtenues semblent montrer que les filtres appris dans la première couche du réseau permettent la détection d'orientations ou des contours. \n",
    "\n",
    "<b>A faire : </b> Affichez et commentez les cartes issues des couches 0 à 5\n",
    "\n",
    "\n",
    "<h4>Visualisation des filtres</h4>\n",
    "\n",
    "La visualisation des filtres de la couche d'entrée est relativement immédiate puisque que les filtres ont le même nombre de channels que les données d'entrée. Autrement dit, les filtres de la première couche sont définis sur le même domaine que les données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_YMjW4AT-HWc"
   },
   "outputs": [],
   "source": [
    "# Récupère tous les paramètres appris par le réseau\n",
    "weights = model2.get_weights()\n",
    "\n",
    "for w in weights: print(w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqAT1-YRMuGL"
   },
   "source": [
    "<b>A faire : </b> A quoi correspondent chaque ligne issues de l'affichage de la cellule précédente ?\n",
    "\n",
    "Affichons maintenant les filtres de la première couche de convolution :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L4Us2w4-M5YV"
   },
   "outputs": [],
   "source": [
    "# normalize values between 0 and 1\n",
    "minimum, maximum = np.min(weights[0]), np.max(weights[0])\n",
    "weights0 = (weights[0] - minimum) / (maximum - minimum)\n",
    "\n",
    "print(minimum, maximum)\n",
    "# entre 0 et 255 pour l'affichage\n",
    "weights0 *= 255.\n",
    "\n",
    "images = []\n",
    "for i in range(64):\n",
    "  images.append(np.array(255*weights0[:,:,:,i]).reshape(5,5).astype('uint8'))\n",
    "\n",
    "show_images(images, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CrEXlY3pTI3E"
   },
   "source": [
    "<h3> CNN pour des images naturelles </h3>\n",
    "\n",
    "Les filtres de convolutions appris sur les données MNIST ne sont pas très parlantes, intéressons nous plutôt à un réseau (beaucoup plus profond) adapté à la classification d'images naturelles. Nous allons considérer pour cela le réseau VGG16, pré-entrainé sur le dataset ImageNet (cf cours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVuyJhICTIIL"
   },
   "outputs": [],
   "source": [
    "!wget https://pageperso.lis-lab.fr/stephane.ayache/cat.jpg\n",
    "!wget https://pageperso.lis-lab.fr/stephane.ayache/imagenet_class_index.json \n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import json\n",
    "\n",
    "# Récupération du modèle complet VGG16\n",
    "model3 = VGG16(include_top=True, weights='imagenet')\n",
    "#print(model3.summary())\n",
    "\n",
    "# chargement d'un dictionnaire qui met en correspondant l'index d'une classe ImageNet et son nom\n",
    "with open('imagenet_class_index.json') as f:\n",
    "    CLASS_INDEX = json.load(f)\n",
    "\n",
    "# chargement et preprocess de l'image (dont normalisation et redimensionnement)\n",
    "img_path = 'cat.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# prédiction et affichage de la classe de probabilité maximale\n",
    "softmax_output = model3.predict(x)\n",
    "best_class = np.argmax(softmax_output)\n",
    "im_class = CLASS_INDEX[str(best_class)][1]\n",
    "print(\"prediction: \", im_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hy49stywZY7Y"
   },
   "source": [
    "Notre chaton a été reconnu comme un chat ? Alors tout va bien, et regardons les filtres de la première couche ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SV8fKj8naJhn"
   },
   "outputs": [],
   "source": [
    "weights = model3.get_weights()\n",
    "#for w in weights: print(w.shape)\n",
    "  \n",
    "# normalize values between 0 and 1\n",
    "minimum, maximum = np.min(weights[0]), np.max(weights[0])\n",
    "weights0 = (weights[0] - minimum) / (maximum - minimum)\n",
    "\n",
    "print(minimum, maximum)\n",
    "# entre 0 et 255 pour l'affichage\n",
    "weights0 *= 255.\n",
    "\n",
    "images = []\n",
    "for i in range(64):\n",
    "  images.append(np.array(255*weights0[:,:,:,i]).reshape(3,3,3).astype('uint8'))\n",
    "\n",
    "show_images(images, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zqUT5x04cjnm"
   },
   "source": [
    "Notez qu'on affiche ici les fltres en RGB alors qu'on pourrait les afficher en séparant les channels. Dans tous les cas, cette visualisation reste peu informative, pour mieux comprendre le rôle d'une couche de convolution, d'autres méthodes sont plus efficaces (cf cours précédent). Ci dessous, nous allons générer une image qui maximise la valeur d'une carte d'activation (réponse à un filtre).\n",
    "\n",
    "<h3> Visualisation par maximisation d'activations</h3>\n",
    "  \n",
    "Les fonctions Tensorflow du backend Keras nous permettent de définir une fonction d'une image vers les activations d'une carte d'une couche de convolution. Maximiser cette fonction en suivant le gradient de la sortie par rapport aux entrées, revient à déterminer une image (artificielle) dont VGG16 obtient une forte réponse à la convolution du filtre ciblé. L'image produite va être composée du \"pattern\" reconnu par le filtre...\n",
    "\n",
    "D'abord, quelques fonctions utiles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nizHh4DMeC1"
   },
   "outputs": [],
   "source": [
    "def deprocess_image(x);\n",
    "# normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "    \n",
    "    return x * 255.\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n",
    "  \n",
    "\n",
    "print(model3.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTEB1Sk5QvcB"
   },
   "source": [
    "Définition d'une fonction en Keras ; obtention du gradient ; gradient ascent pour maximiser ; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HD1QKInV7iA1"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "num_filter = 2\n",
    "\n",
    "# entrée de la fonction à maximiser = entrée du réseau VGG = une image\n",
    "input_img = model3.layers[0].input\n",
    "\n",
    "# sortie = Somme (moyenne) des activations d'une carte de convolution associée au filtre num_filter\n",
    "output = K.mean(model3.layers[14].output[:, :, :, num_filter])\n",
    "\n",
    "# returns the gradients of output w.r.t. input\n",
    "grads = K.gradients(output, input_img)[0]\n",
    "grads = normalize(grads)\n",
    "\n",
    "# fonction : input -> output, gradients \n",
    "func = K.function([input_img], [output, grads])\n",
    "\n",
    "## gradient ascent ##\n",
    "\n",
    "# point de départ aléatoire\n",
    "x = np.random.random((1, 224, 224, 3)) * 255.\n",
    "x = preprocess_input(x)\n",
    "\n",
    "for i in range(40): # 40 iterations\n",
    "    loss_value, grads_value = func([x])\n",
    "    x += grads_value * 10\n",
    "\n",
    "    print('Current loss value:', loss_value)\n",
    "    if loss_value <= 0.:\n",
    "        # some filters get stuck to 0\n",
    "        break\n",
    "\n",
    "# point d'arrivée : conversion en RGB puis affichage\n",
    "xx = deprocess_image(x)\n",
    "\n",
    "from PIL import Image\n",
    "print(xx.shape)\n",
    "display(Image.fromarray(xx[0].astype('uint8')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lCkmkql8ahOv"
   },
   "source": [
    "<b> A faire : </b> variez les couches et les filtres, puis commentez vos résultats obtenus. Comment obtenir des motifs encore plus complexes ?\n",
    "\n",
    "<h2> Entrainement d'un réseau très profond </h2>\n",
    "\n",
    "Un réseau très profond tel que VGG contient énormément de paramètres, son entrainement peu s'avérer compliquer. Tous les paramètres doivent entrer en mémoire (RAM ou GPU), ainsi que toutes les données d'un minibatch. Dans le cas d'images relativement volumineuses (ie: Imagenet =255x255x3), la taille du minibatch est souvent ainsi très couteux en mémoire et se voit ainsi réduit à quelques images, rendant l'entrainement encore plus long... \n",
    "\n",
    "Souvent, de grandes bases de données ne sont pas disponibles. Dans ce cas, pour parvenir à entrainer un tel réseau avec peu d'images, plusieurs options sont possibles :\n",
    "- partir d'un réseau déjà (pré-)entrainé, et/ou utiliser ses poids pour initialiser un autre réseau qui sera appris sur une base (réduite) d'images (= finetuning, très efficace)\n",
    "- régulariser les poids du réseau (peut aider mais ne suffit pas)\n",
    "- augmenter artificiellement le nombre de données (améliore toujours les performances d'un réseau)\n",
    "\n",
    "Dans la suite, nous illustrons ce dernier point sur les données MNIST.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nOWqj7Jafn4f"
   },
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "nb_samples = len(x_train)\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Sélection aléatoire de 5000 exemples\n",
    "l_idx = list(range(nb_samples))\n",
    "np.random.shuffle(l_idx) \n",
    "l_idx = l_idx[:5000]\n",
    "x_train, y_train = x_train[l_idx], y_train[l_idx]\n",
    "\n",
    "# conversion des étiquettes au format one-hot vector\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "# Architecture du modèle\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(64, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu', input_shape=input_shape))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "model2.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "model2.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#print(model2.summary())\n",
    "\n",
    "model2.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1)\n",
    "\n",
    "score = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"score=\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UyYs5MIy9gJ"
   },
   "source": [
    "La performance obtenue peut être améliorée en augmentant les données. La cellule suivante génère 20000 données à partir des 5000 utilisées jusque là.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNiXpD4ay-Ay"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# déclaration d'un générateur, qui transformera \"à la volée\" des données MNIST \n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=10,\n",
    "    zoom_range = 0.05, \n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    horizontal_flip=False, # flip horizontal et vertical n'ont pas de sens pour des digits !\n",
    "    vertical_flip=False\n",
    "    )\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# On instancie le générateur\n",
    "flow = datagen.flow(x_train, y_train, batch_size=128, shuffle=True)\n",
    "\n",
    "# Pour affichage : une itération du générateur\n",
    "xx = next(flow)\n",
    "print(xx[0].shape, xx[1].shape)\n",
    "\n",
    "images = []\n",
    "for i in range(64):\n",
    "  images.append(np.array(255*xx[0][i,:,:,:]).reshape(28,28).astype('uint8'))\n",
    "show_images(images, 8)\n",
    "\n",
    "\n",
    "# réinitialisation du modèle\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(64, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu', input_shape=input_shape))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "model2.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "model2.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# entrainement avec les données augmentées (à la volée)\n",
    "model2.fit_generator(datagen.flow(x_train, y_train, batch_size=128), steps_per_epoch=int(20000/128), epochs=20)\n",
    "\n",
    "# évaluation\n",
    "score = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"score=\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9MCbzBFfFwcf"
   },
   "source": [
    "<b>A faire : </b> testez d'autres formes d'augmentation et d'autres quantités pour constater l'impact sur la précision du réseau."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TP3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
